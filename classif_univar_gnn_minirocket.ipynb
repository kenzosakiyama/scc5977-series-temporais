{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwuzKEIJvrdB"
   },
   "source": [
    "# Parâmetros do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c5cK7y9Xvvwv"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/motionsense.csv'\n",
    "LOG_PATH = 'evaluation/gnn_minirocket/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A6_F-loJv2g3"
   },
   "outputs": [],
   "source": [
    "FEATURES = ['userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z']\n",
    "SEED = 2024\n",
    "K = 1\n",
    "K_NEIGHBORS = 5\n",
    "EPOCHS = 200\n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5FGFRP-4PwFC"
   },
   "outputs": [],
   "source": [
    "# pontos sao problematicos\n",
    "FEATURES = [feat.replace('.', '_') for feat in FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT3iJ-NetpDH"
   },
   "source": [
    "# Carregando os dados processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d8hgqmbOtc3x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qlHygf0lxXpm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "Q7CBt92Bxenm",
    "outputId": "e1f1bba1-524c-402c-a20e-cbce0d87c418"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>act</th>\n",
       "      <th>id</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.759611</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
       "0       1.528132       -0.733896      0.696372   0.741895   0.669768   \n",
       "1       1.527992       -0.716987      0.677762   0.753099   0.657116   \n",
       "2       1.527765       -0.706999      0.670951   0.759611   0.649555   \n",
       "3       1.516768       -0.704678      0.675735   0.760709   0.647788   \n",
       "4       1.493941       -0.703918      0.672994   0.760062   0.647210   \n",
       "\n",
       "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
       "0  -0.031672        0.316738        0.778180        1.082764   \n",
       "1  -0.032255        0.842032        0.424446        0.643574   \n",
       "2  -0.032707       -0.138143       -0.040741        0.343563   \n",
       "3  -0.041140       -0.025005       -1.048717        0.035860   \n",
       "4  -0.058530        0.114253       -0.912890        0.047341   \n",
       "\n",
       "   userAcceleration.x  userAcceleration.y  userAcceleration.z  act   id  trial  \n",
       "0            0.294894           -0.184493            0.377542  0.0  0.0    1.0  \n",
       "1            0.219405            0.035846            0.114866  0.0  0.0    1.0  \n",
       "2            0.010714            0.134701           -0.167808  0.0  0.0    1.0  \n",
       "3           -0.008389            0.136788            0.094958  0.0  0.0    1.0  \n",
       "4            0.199441            0.353996           -0.044299  0.0  0.0    1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rToPntyzxfMN",
    "outputId": "f921125c-5282-414e-f089-bb3a4facefaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1412865 entries, 0 to 1412864\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   attitude.roll       1412865 non-null  float64\n",
      " 1   attitude.pitch      1412865 non-null  float64\n",
      " 2   attitude.yaw        1412865 non-null  float64\n",
      " 3   gravity.x           1412865 non-null  float64\n",
      " 4   gravity.y           1412865 non-null  float64\n",
      " 5   gravity.z           1412865 non-null  float64\n",
      " 6   rotationRate.x      1412865 non-null  float64\n",
      " 7   rotationRate.y      1412865 non-null  float64\n",
      " 8   rotationRate.z      1412865 non-null  float64\n",
      " 9   userAcceleration.x  1412865 non-null  float64\n",
      " 10  userAcceleration.y  1412865 non-null  float64\n",
      " 11  userAcceleration.z  1412865 non-null  float64\n",
      " 12  act                 1412865 non-null  float64\n",
      " 13  id                  1412865 non-null  float64\n",
      " 14  trial               1412865 non-null  float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 172.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqH2AcebyCpw",
    "outputId": "177ed8dc-379b-4dc7-ab82-db3bd02eb167"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['act'].nunique() # lembrar de mapear id para string da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [\n",
    "    np.load('evaluation/ddtw/userAcceleration-x_distances.npy'),\n",
    "    np.load('evaluation/ddtw/userAcceleration-y_distances.npy'),\n",
    "    np.load('evaluation/ddtw/userAcceleration-z_distances.npy')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paDloZmq0t1-"
   },
   "source": [
    "# Separando pares X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afnzw1bkvAlw",
    "outputId": "6e4015f6-64a0-4e85-98f7-8f7fdd57dd18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['act'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LywM8DtAuhCA"
   },
   "outputs": [],
   "source": [
    "subject_id = 1\n",
    "act_id = 0\n",
    "subject_mask = df['id'] == subject_id\n",
    "act_mask = df['act'] == act_id\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label in df['act'].unique():\n",
    "  for subj_id in df['id'].unique():\n",
    "    subj_mask = df['id'] == subj_id\n",
    "    act_mask = df['act'] == label\n",
    "    filtered_df = df[subj_mask & act_mask].reset_index()\n",
    "\n",
    "    X.append(\n",
    "        np.stack(\n",
    "            [\n",
    "              filtered_df['userAcceleration.x'].values,\n",
    "              filtered_df['userAcceleration.y'].values,\n",
    "              filtered_df['userAcceleration.z'].values\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ixl_XrH2mlTb",
    "outputId": "651b3bcf-5eb6-4a3f-c7ad-fa65e87c16d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = np.unique(y).shape[0]\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPaupwFKt3F6"
   },
   "source": [
    "# Extraindo features usando o MiniRocket\n",
    "\n",
    "Inpirado no [tutorial](https://www.aeon-toolkit.org/en/stable/examples/transformations/minirocket.html#MiniRocket). Rocket requer que as séries tenham o mesmo tamanho (comprimento). Então, fazemos [padding](https://www.aeon-toolkit.org/en/stable/api_reference/auto_generated/aeon.transformations.collection.pad.PaddingTransformer.html) com zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg0TM6um6LwB",
    "outputId": "b12361e0-6574-4648-df42-8834bc07260a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenzosaki/miniconda3/envs/ts/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n",
      "/home/kenzosaki/miniconda3/envs/ts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from aeon.transformations.collection.convolution_based import MiniRocket, Rocket\n",
    "from aeon.transformations.collection import PaddingTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuaIvJYlwg0t",
    "outputId": "a6e899aa-6b4e-400e-d409-2684694fd285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Processing channel 0: userAcceleration_x.\n",
      "- Processing channel 1: userAcceleration_y.\n",
      "- Processing channel 2: userAcceleration_z.\n"
     ]
    }
   ],
   "source": [
    "univar_X_processed = []\n",
    "for channel in range(len(FEATURES)):\n",
    "  print(f'- Processing channel {channel}: {FEATURES[channel]}.')\n",
    "  X_curr = [np.expand_dims(example[channel], axis=0) for example in X]\n",
    "  transformer = PaddingTransformer() # é necessário que todas as séries tenham o mesmo tamanho\n",
    "  minirocket = MiniRocket(num_kernels=10_000, n_jobs=5, random_state=SEED)  # por padrao, MiniRocket usa ~10_000 kernels\n",
    "  X_padded = transformer.fit_transform(X_curr)\n",
    "  X_features = minirocket.fit_transform(X_padded)\n",
    "  univar_X_processed.append(X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up95pDNY8gk_"
   },
   "source": [
    "# Criando grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tK4ExB9LxzXl"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ir5nj2uxzXn",
    "outputId": "790a8c75-e60c-4394-e427-08c6c4e02a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Using k=5\n"
     ]
    }
   ],
   "source": [
    "adj_lists = [kneighbors_graph(univar_X_processed[channel], n_neighbors=K_NEIGHBORS, n_jobs=-1, include_self=False) for channel in range(len(FEATURES))]\n",
    "print(f'- Using k={K_NEIGHBORS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2kWgAPbx8TZ"
   },
   "source": [
    "# Integrando com networkX e PyG \n",
    "\n",
    "[Referencia](https://pytorch-geometric.readthedocs.io/en/2.5.1/notes/heterogeneous.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vbHZOQx_x8Tb"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.seed import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_from_adj_list(adj_list: np.array, features: np.array) -> Data:\n",
    "\n",
    "    G = nx.from_numpy_array(adj_list)\n",
    "\n",
    "    # print(nx.number_connected_components(G))\n",
    "\n",
    "    for i, feat in enumerate(features):\n",
    "        G.nodes[i]['features'] = feat\n",
    "\n",
    "    return from_networkx(G, group_node_attrs='features')\n",
    "\n",
    "def create_data_from_distances(distances: np.array, features: np.array) -> Data:\n",
    "\n",
    "    # adicionando inf na diagonal principal - nao escolher a si mesmo\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "\n",
    "    # verirficar quem são os top k vizinhos\n",
    "    adj_list = np.zeros_like(distances)\n",
    "\n",
    "    for i in range(distances.shape[0]):\n",
    "\n",
    "        top_k = np.argsort(distances[i])[:K_NEIGHBORS]\n",
    "        adj_list[i, top_k] = 1\n",
    "    \n",
    "    # criando o grafo do nx\n",
    "    G = nx.from_numpy_array(adj_list)\n",
    "\n",
    "    # print(nx.number_connected_components(G))\n",
    "\n",
    "    for i, feat in enumerate(features):\n",
    "        G.nodes[i]['features'] = feat\n",
    "\n",
    "    return from_networkx(G, group_node_attrs='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.create_data_from_adj_list(adj_list: <built-in function array>, features: <built-in function array>) -> torch_geometric.data.data.Data>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_data_from_adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo funções de treino e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, \n",
    "          optimizer: torch.optim.Optimizer, \n",
    "          data: Data, \n",
    "          X_train_ids: np.array, \n",
    "          y_train: np.array, \n",
    "          device: torch.device = torch.device('cpu')) -> float:\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    data = data.to(device)\n",
    "    out = model(data.x, data.edge_index)\n",
    "    # print(out.shape, out[X_train_ids].shape, y_train.shape)\n",
    "    loss = F.cross_entropy(out[X_train_ids], y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model: nn.Module, \n",
    "         data: Data, \n",
    "         X_test_ids: np.array, \n",
    "         y_test: np.array, \n",
    "         device: torch.device = torch.device('cpu')) -> float:\n",
    "\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pred = logits[X_test_ids].softmax(dim=-1).argmax(dim=-1)\n",
    "    loss = F.cross_entropy(logits[X_test_ids], y_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "\n",
    "    metrics = {'accuracy': acc,\n",
    "               'macro_f1': f1}\n",
    "\n",
    "    return float(loss), metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrando treino e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch_geometric.nn import GCN, GAT\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gnn_classifier(data: Data, y: np.array, k: int = 5, verbose: bool = False, device: torch.device = torch.device('cpu')) -> dict[str, list[int]]:\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "\n",
    "    folds_accuracy = []\n",
    "    folds_f1 = []\n",
    "\n",
    "    # X pode ser apenas um placeholder, estamos usando um cenário transdutivo\n",
    "    X = np.zeros_like(y)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        # X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index] # n da para ter um np array com dimensoes diferentes :(\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # convertendo labels para tensores\n",
    "        y_train = torch.LongTensor(y_train)\n",
    "        y_test = torch.LongTensor(y_test)\n",
    "\n",
    "        # instanciando modelo\n",
    "        # TODO: expor hiperparâmetros como argumentos\n",
    "        model = GCN(\n",
    "            in_channels=data.x.shape[1], # dimensões das features\n",
    "            hidden_channels=64,\n",
    "            num_layers=1,\n",
    "            dropout=0.2,\n",
    "            out_channels=n_labels\n",
    "        )\n",
    "\n",
    "        # model = GAT(\n",
    "        #     in_channels=data.x.shape[1], # dimensões das features\n",
    "        #     hidden_channels=64,\n",
    "        #     num_layers=1,\n",
    "        #     heads=4,\n",
    "        #     dropout=0.3,\n",
    "        #     out_channels=n_labels\n",
    "        # )\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "        # laço de treino\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "            train(model, optimizer, data, train_index, y_train, device)\n",
    "            _, metrics = test(model, data, test_index, y_test, device)\n",
    "            # if verbose: print(f'- Epoch {epoch} metrics: {metrics}')\n",
    "\n",
    "        # obtendo as métricas da ultima epoca\n",
    "        acc = metrics['accuracy']\n",
    "        f1 = metrics['macro_f1']\n",
    "\n",
    "        folds_accuracy.append(acc)\n",
    "        folds_f1.append(f1)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"- Fold {i + 1} full report\")\n",
    "            print(metrics)\n",
    "    \n",
    "    return {'accuracy': folds_accuracy, 'macro_f1': folds_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate channel 0 - userAcceleration_x\n",
      "\t- mean accuracy: 0.862 +/- 0.000\n",
      "\t- mean f1: 0.878 +/- 0.000\n",
      "Univariate channel 1 - userAcceleration_y\n",
      "\t- mean accuracy: 0.724 +/- 0.000\n",
      "\t- mean f1: 0.737 +/- 0.000\n",
      "Univariate channel 2 - userAcceleration_z\n",
      "\t- mean accuracy: 0.759 +/- 0.000\n",
      "\t- mean f1: 0.764 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "# cenário univariado\n",
    "for i in range(len(FEATURES)):\n",
    "    print(f'Univariate channel {i} - {FEATURES[i]}')\n",
    "    data = create_data_from_adj_list(adj_lists[i], univar_X_processed[i])\n",
    "    # data = create_data_from_distances(distances[i], univar_X_processed[i])\n",
    "    metrics = evaluate_gnn_classifier(data, y, k=K, verbose=False, device=device)\n",
    "    print(f\"\\t- mean accuracy: {np.mean(metrics['accuracy']):.3f} +/- {np.std(metrics['accuracy']):.3f}\")\n",
    "    print(f\"\\t- mean f1: {np.mean(metrics['macro_f1']):.3f} +/- {np.std(metrics['macro_f1']):.3f}\")\n",
    "    \n",
    "    if SAVE:\n",
    "        with open(f'{LOG_PATH}univariate_{FEATURES[i]}.json', 'w') as f:\n",
    "            json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
