{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwuzKEIJvrdB"
   },
   "source": [
    "# Parâmetros do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c5cK7y9Xvvwv"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/motionsense.csv'\n",
    "LOG_PATH = 'evaluation/gnn_minirocket/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A6_F-loJv2g3"
   },
   "outputs": [],
   "source": [
    "FEATURES = ['userAcceleration.x', 'userAcceleration.y', 'userAcceleration.z']\n",
    "SEED = 2024\n",
    "K = 10\n",
    "K_NEIGHBORS = 5\n",
    "EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5FGFRP-4PwFC"
   },
   "outputs": [],
   "source": [
    "# pontos sao problematicos\n",
    "FEATURES = [feat.replace('.', '_') for feat in FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT3iJ-NetpDH"
   },
   "source": [
    "# Carregando os dados processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "d8hgqmbOtc3x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qlHygf0lxXpm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "Q7CBt92Bxenm",
    "outputId": "e1f1bba1-524c-402c-a20e-cbce0d87c418"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll</th>\n",
       "      <th>attitude.pitch</th>\n",
       "      <th>attitude.yaw</th>\n",
       "      <th>gravity.x</th>\n",
       "      <th>gravity.y</th>\n",
       "      <th>gravity.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>act</th>\n",
       "      <th>id</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.528132</td>\n",
       "      <td>-0.733896</td>\n",
       "      <td>0.696372</td>\n",
       "      <td>0.741895</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>-0.031672</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.527992</td>\n",
       "      <td>-0.716987</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.657116</td>\n",
       "      <td>-0.032255</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.527765</td>\n",
       "      <td>-0.706999</td>\n",
       "      <td>0.670951</td>\n",
       "      <td>0.759611</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>-0.032707</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.516768</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>0.675735</td>\n",
       "      <td>0.760709</td>\n",
       "      <td>0.647788</td>\n",
       "      <td>-0.041140</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.493941</td>\n",
       "      <td>-0.703918</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.760062</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll  attitude.pitch  attitude.yaw  gravity.x  gravity.y  \\\n",
       "0       1.528132       -0.733896      0.696372   0.741895   0.669768   \n",
       "1       1.527992       -0.716987      0.677762   0.753099   0.657116   \n",
       "2       1.527765       -0.706999      0.670951   0.759611   0.649555   \n",
       "3       1.516768       -0.704678      0.675735   0.760709   0.647788   \n",
       "4       1.493941       -0.703918      0.672994   0.760062   0.647210   \n",
       "\n",
       "   gravity.z  rotationRate.x  rotationRate.y  rotationRate.z  \\\n",
       "0  -0.031672        0.316738        0.778180        1.082764   \n",
       "1  -0.032255        0.842032        0.424446        0.643574   \n",
       "2  -0.032707       -0.138143       -0.040741        0.343563   \n",
       "3  -0.041140       -0.025005       -1.048717        0.035860   \n",
       "4  -0.058530        0.114253       -0.912890        0.047341   \n",
       "\n",
       "   userAcceleration.x  userAcceleration.y  userAcceleration.z  act   id  trial  \n",
       "0            0.294894           -0.184493            0.377542  0.0  0.0    1.0  \n",
       "1            0.219405            0.035846            0.114866  0.0  0.0    1.0  \n",
       "2            0.010714            0.134701           -0.167808  0.0  0.0    1.0  \n",
       "3           -0.008389            0.136788            0.094958  0.0  0.0    1.0  \n",
       "4            0.199441            0.353996           -0.044299  0.0  0.0    1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rToPntyzxfMN",
    "outputId": "f921125c-5282-414e-f089-bb3a4facefaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1412865 entries, 0 to 1412864\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   attitude.roll       1412865 non-null  float64\n",
      " 1   attitude.pitch      1412865 non-null  float64\n",
      " 2   attitude.yaw        1412865 non-null  float64\n",
      " 3   gravity.x           1412865 non-null  float64\n",
      " 4   gravity.y           1412865 non-null  float64\n",
      " 5   gravity.z           1412865 non-null  float64\n",
      " 6   rotationRate.x      1412865 non-null  float64\n",
      " 7   rotationRate.y      1412865 non-null  float64\n",
      " 8   rotationRate.z      1412865 non-null  float64\n",
      " 9   userAcceleration.x  1412865 non-null  float64\n",
      " 10  userAcceleration.y  1412865 non-null  float64\n",
      " 11  userAcceleration.z  1412865 non-null  float64\n",
      " 12  act                 1412865 non-null  float64\n",
      " 13  id                  1412865 non-null  float64\n",
      " 14  trial               1412865 non-null  float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 172.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqH2AcebyCpw",
    "outputId": "177ed8dc-379b-4dc7-ab82-db3bd02eb167"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['act'].nunique() # lembrar de mapear id para string da classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paDloZmq0t1-"
   },
   "source": [
    "# Separando pares X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afnzw1bkvAlw",
    "outputId": "6e4015f6-64a0-4e85-98f7-8f7fdd57dd18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['act'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LywM8DtAuhCA"
   },
   "outputs": [],
   "source": [
    "subject_id = 1\n",
    "act_id = 0\n",
    "subject_mask = df['id'] == subject_id\n",
    "act_mask = df['act'] == act_id\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for label in df['act'].unique():\n",
    "  for subj_id in df['id'].unique():\n",
    "    subj_mask = df['id'] == subj_id\n",
    "    act_mask = df['act'] == label\n",
    "    filtered_df = df[subj_mask & act_mask].reset_index()\n",
    "\n",
    "    X.append(\n",
    "        np.stack(\n",
    "            [\n",
    "              filtered_df['userAcceleration.x'].values,\n",
    "              filtered_df['userAcceleration.y'].values,\n",
    "              filtered_df['userAcceleration.z'].values\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ixl_XrH2mlTb",
    "outputId": "651b3bcf-5eb6-4a3f-c7ad-fa65e87c16d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = np.unique(y).shape[0]\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPaupwFKt3F6"
   },
   "source": [
    "# Extraindo features usando o MiniRocket\n",
    "\n",
    "Inpirado no [tutorial](https://www.aeon-toolkit.org/en/stable/examples/transformations/minirocket.html#MiniRocket). Rocket requer que as séries tenham o mesmo tamanho (comprimento). Então, fazemos [padding](https://www.aeon-toolkit.org/en/stable/api_reference/auto_generated/aeon.transformations.collection.pad.PaddingTransformer.html) com zeros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg0TM6um6LwB",
    "outputId": "b12361e0-6574-4648-df42-8834bc07260a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenzosaki/miniconda3/envs/ts/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n",
      "/home/kenzosaki/miniconda3/envs/ts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "from aeon.transformations.collection.convolution_based import MiniRocket, Rocket\n",
    "from aeon.transformations.collection import PaddingTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuaIvJYlwg0t",
    "outputId": "a6e899aa-6b4e-400e-d409-2684694fd285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Processing channel 0: userAcceleration_x.\n",
      "- Processing channel 1: userAcceleration_y.\n",
      "- Processing channel 2: userAcceleration_z.\n"
     ]
    }
   ],
   "source": [
    "univar_X_processed = []\n",
    "for channel in range(len(FEATURES)):\n",
    "  print(f'- Processing channel {channel}: {FEATURES[channel]}.')\n",
    "  X_curr = [np.expand_dims(example[channel], axis=0) for example in X]\n",
    "  transformer = PaddingTransformer() # é necessário que todas as séries tenham o mesmo tamanho\n",
    "  minirocket = MiniRocket(num_kernels=10_000, n_jobs=5, random_state=SEED)  # por padrao, MiniRocket usa ~10_000 kernels\n",
    "  X_padded = transformer.fit_transform(X_curr)\n",
    "  X_features = minirocket.fit_transform(X_padded)\n",
    "  univar_X_processed.append(X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up95pDNY8gk_"
   },
   "source": [
    "# Criando grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tK4ExB9LxzXl"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ir5nj2uxzXn",
    "outputId": "790a8c75-e60c-4394-e427-08c6c4e02a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Using k=5\n"
     ]
    }
   ],
   "source": [
    "adj_lists = [kneighbors_graph(univar_X_processed[channel], n_neighbors=K_NEIGHBORS, n_jobs=-1, include_self=False) for channel in range(len(FEATURES))]\n",
    "print(f'- Using k={K_NEIGHBORS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2kWgAPbx8TZ"
   },
   "source": [
    "# Integrando com networkX e PyG \n",
    "\n",
    "[Referencia](https://pytorch-geometric.readthedocs.io/en/2.5.1/notes/heterogeneous.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vbHZOQx_x8Tb"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.seed import seed_everything\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_from_adj_list(adj_list: np.array, features: np.array) -> Data:\n",
    "\n",
    "    data = HeteroData()\n",
    "\n",
    "    # adicionando features\n",
    "    for i, feat in enumerate(FEATURES):\n",
    "        data[feat].x = torch.Tensor((features[i])).float()\n",
    "\n",
    "    # adicionando arestas de cada grafo\n",
    "    for label, adj_list in zip(FEATURES, adj_lists):\n",
    "\n",
    "        adj_list = adj_list.toarray()\n",
    "        sources = []\n",
    "        targets = []\n",
    "\n",
    "        for i in range(adj_list.shape[0]):\n",
    "            neighbors = np.where(adj_list[i].astype(int) == 1)[0]\n",
    "            sources.extend([i] * len(neighbors))\n",
    "            targets.extend(neighbors.tolist())\n",
    "\n",
    "        # revertendo arestas\n",
    "        s_copy = sources.copy()\n",
    "        t_copy = targets.copy()\n",
    "\n",
    "        sources.extend(t_copy)\n",
    "        targets.extend(s_copy)\n",
    "\n",
    "        edges = torch.LongTensor([sources, targets])\n",
    "        data[label, f\"{label}_neighbor\", label].edge_index = edges\n",
    "    \n",
    "\n",
    "    # https://github.com/pyg-team/pytorch_geometric/issues/3604\n",
    "    # conectando arestas de todos os tipos\n",
    "    # a feature do tipo X do no BLAU tem que estar conectada com a feature do tipo Y do mesmo nó BLAU\n",
    "    sources = [i for i in range(len(features[0]))]\n",
    "    targets = sources.copy()\n",
    "\n",
    "    edges = torch.LongTensor([sources, targets])\n",
    "\n",
    "    # conectando todas as features do mesmo nó\n",
    "    for feat_source in FEATURES:\n",
    "        for feat_dest in FEATURES:\n",
    "            # nao adicionar self-loop\n",
    "            if feat_source == feat_dest: continue\n",
    "            data[feat_source, \"is_the_same\", feat_dest].edge_index = edges\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data_from_adj_list(adj_lists, univar_X_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  userAcceleration_x={ x=[144, 9996] },\n",
       "  userAcceleration_y={ x=[144, 9996] },\n",
       "  userAcceleration_z={ x=[144, 9996] },\n",
       "  (userAcceleration_x, userAcceleration_x_neighbor, userAcceleration_x)={ edge_index=[2, 1440] },\n",
       "  (userAcceleration_y, userAcceleration_y_neighbor, userAcceleration_y)={ edge_index=[2, 1440] },\n",
       "  (userAcceleration_z, userAcceleration_z_neighbor, userAcceleration_z)={ edge_index=[2, 1440] },\n",
       "  (userAcceleration_x, is_the_same, userAcceleration_y)={ edge_index=[2, 144] },\n",
       "  (userAcceleration_x, is_the_same, userAcceleration_z)={ edge_index=[2, 144] },\n",
       "  (userAcceleration_y, is_the_same, userAcceleration_x)={ edge_index=[2, 144] },\n",
       "  (userAcceleration_y, is_the_same, userAcceleration_z)={ edge_index=[2, 144] },\n",
       "  (userAcceleration_z, is_the_same, userAcceleration_x)={ edge_index=[2, 144] },\n",
       "  (userAcceleration_z, is_the_same, userAcceleration_y)={ edge_index=[2, 144] }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['userAcceleration_x', 'userAcceleration_y', 'userAcceleration_z'],\n",
       " [('userAcceleration_x', 'userAcceleration_x_neighbor', 'userAcceleration_x'),\n",
       "  ('userAcceleration_y', 'userAcceleration_y_neighbor', 'userAcceleration_y'),\n",
       "  ('userAcceleration_z', 'userAcceleration_z_neighbor', 'userAcceleration_z'),\n",
       "  ('userAcceleration_x', 'is_the_same', 'userAcceleration_y'),\n",
       "  ('userAcceleration_x', 'is_the_same', 'userAcceleration_z'),\n",
       "  ('userAcceleration_y', 'is_the_same', 'userAcceleration_x'),\n",
       "  ('userAcceleration_y', 'is_the_same', 'userAcceleration_z'),\n",
       "  ('userAcceleration_z', 'is_the_same', 'userAcceleration_x'),\n",
       "  ('userAcceleration_z', 'is_the_same', 'userAcceleration_y')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo GNN Heterogênea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import HGTConv, HANConv, HEATConv, HeteroLayerNorm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeterogeneousGNN(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, data: HeteroData,\n",
    "                     in_channels: int,\n",
    "                     out_channels: int,\n",
    "                     layers: int = 2,\n",
    "                     heads: int = 4,\n",
    "                     dropout: float = 0.2,\n",
    "                     hidden_channels: int = 32):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    # self.gnn1 = HGTConv(\n",
    "    #     in_channels, # dimensões das features\n",
    "    #     out_channels=hidden_channels,\n",
    "    #     heads=heads,\n",
    "    #     metadata=data.metadata(),\n",
    "    # )\n",
    "\n",
    "    self.gnn1 = HANConv(\n",
    "        in_channels, # dimensões das features\n",
    "        out_channels=hidden_channels,\n",
    "        heads=heads,\n",
    "        metadata=data.metadata(),\n",
    "        dropout=dropout\n",
    "    )\n",
    "\n",
    "\n",
    "    # self.classifier = nn.Linear(hidden_channels, out_channels)\n",
    "    self.classifier = nn.Linear(len(data.metadata()[0])*hidden_channels, out_channels)\n",
    "\n",
    "  def forward(self, X, edge_index):\n",
    "\n",
    "    gnn_embds = self.gnn1(X, edge_index)\n",
    "    # gnn_embds = self.gnn2(gnn_embds, edge_index)\n",
    "\n",
    "    # agregando via media\n",
    "    # agg_embs = torch.stack([embs for embs in gnn_embds.values()]).mean(axis=0)\n",
    "\n",
    "    # agregando via concatenação\n",
    "    agg_embs = torch.concat([embs for embs in gnn_embds.values()], dim=1)\n",
    "\n",
    "    out = self.classifier(agg_embs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo funções de treino e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, \n",
    "          optimizer: torch.optim.Optimizer, \n",
    "          scheduler: torch.optim.lr_scheduler,\n",
    "          data: Data, \n",
    "          X_train_ids: np.array, \n",
    "          y_train: np.array, \n",
    "          device: torch.device = torch.device('cpu')) -> float:\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    # print(out.shape, out[X_train_ids].shape, y_train.shape)\n",
    "    loss = F.cross_entropy(out[X_train_ids], y_train)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model: nn.Module, \n",
    "         data: Data, \n",
    "         X_test_ids: np.array, \n",
    "         y_test: np.array, \n",
    "         device: torch.device = torch.device('cpu')) -> float:\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    data = data.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    logits = model(data.x_dict, data.edge_index_dict)\n",
    "    pred = logits[X_test_ids].softmax(dim=-1).argmax(dim=-1)\n",
    "    loss = F.cross_entropy(logits[X_test_ids], y_test)\n",
    "\n",
    "    y_test = y_test.cpu()\n",
    "    pred = pred.cpu()\n",
    "\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "\n",
    "    metrics = {'accuracy': acc,\n",
    "               'macro_f1': f1}\n",
    "\n",
    "    return float(loss), metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrando treino e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch_geometric.nn import GCN, GAT\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gnn_classifier(data: Data, y: np.array, k: int = 5, verbose: bool = False, device: torch.device = torch.device('cpu')) -> dict[str, list[int]]:\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "\n",
    "    folds_accuracy = []\n",
    "    folds_f1 = []\n",
    "\n",
    "    # X pode ser apenas um placeholder, estamos usando um cenário transdutivo\n",
    "    X = np.zeros_like(y)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        # X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index] # n da para ter um np array com dimensoes diferentes :(\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # convertendo labels para tensores\n",
    "        y_train = torch.LongTensor(y_train)\n",
    "        y_test = torch.LongTensor(y_test)\n",
    "\n",
    "        # instanciando modelo\n",
    "        # TODO: expor hiperparâmetros como argumentos\n",
    "        model = HeterogeneousGNN(\n",
    "            data,\n",
    "            in_channels=data.x_dict[FEATURES[0]].shape[1], # dimensões das features),\n",
    "            hidden_channels=32,\n",
    "            layers=1, # nao modifica nd\n",
    "            dropout=0.5,\n",
    "            heads=4,\n",
    "            out_channels=n_labels\n",
    "        )\n",
    "\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=1, epochs=EPOCHS, pct_start=0.1)\n",
    "\n",
    "        # laço de treino\n",
    "        for epoch in tqdm(range(1, EPOCHS + 1), desc=f'Fold {i + 1} epochs'):\n",
    "            train(model, optimizer, scheduler, data, train_index, y_train, device)\n",
    "            _, metrics = test(model, data, test_index, y_test, device)\n",
    "            # if verbose: print(f'- Epoch {epoch} metrics: {metrics}')\n",
    "\n",
    "        # obtendo as métricas da ultima epoca\n",
    "        acc = metrics['accuracy']\n",
    "        f1 = metrics['macro_f1']\n",
    "\n",
    "        folds_accuracy.append(acc)\n",
    "        folds_f1.append(f1)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"- Fold {i + 1} full report\")\n",
    "            print(metrics)\n",
    "    \n",
    "    return {'accuracy': folds_accuracy, 'macro_f1': folds_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 epochs: 100%|██████████| 300/300 [00:07<00:00, 39.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 1 full report\n",
      "{'accuracy': 0.8666666666666667, 'macro_f1': 0.861111111111111}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 epochs: 100%|██████████| 300/300 [00:03<00:00, 96.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 2 full report\n",
      "{'accuracy': 0.8, 'macro_f1': 0.7999999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 epochs: 100%|██████████| 300/300 [00:02<00:00, 128.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 3 full report\n",
      "{'accuracy': 1.0, 'macro_f1': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 epochs: 100%|██████████| 300/300 [00:02<00:00, 124.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 4 full report\n",
      "{'accuracy': 1.0, 'macro_f1': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 epochs: 100%|██████████| 300/300 [00:02<00:00, 128.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 5 full report\n",
      "{'accuracy': 1.0, 'macro_f1': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 6 epochs: 100%|██████████| 300/300 [00:02<00:00, 129.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 6 full report\n",
      "{'accuracy': 0.9285714285714286, 'macro_f1': 0.9333333333333332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 7 epochs: 100%|██████████| 300/300 [00:03<00:00, 95.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 7 full report\n",
      "{'accuracy': 0.7142857142857143, 'macro_f1': 0.7333333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 8 epochs: 100%|██████████| 300/300 [00:02<00:00, 132.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 8 full report\n",
      "{'accuracy': 0.9285714285714286, 'macro_f1': 0.9206349206349206}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 9 epochs: 100%|██████████| 300/300 [00:02<00:00, 133.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 9 full report\n",
      "{'accuracy': 0.7857142857142857, 'macro_f1': 0.7666666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 10 epochs: 100%|██████████| 300/300 [00:02<00:00, 130.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Fold 10 full report\n",
      "{'accuracy': 0.7857142857142857, 'macro_f1': 0.7333333333333334}\n",
      "\t- mean accuracy: 0.881 +/- 0.100\n",
      "\t- mean f1: 0.875 +/- 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Multivar')\n",
    "# data = create_data_from_distances(distances[i], univar_X_processed[i])\n",
    "metrics = evaluate_gnn_classifier(data, y, k=K, verbose=True, device=device)\n",
    "print(f\"\\t- mean accuracy: {np.mean(metrics['accuracy']):.3f} +/- {np.std(metrics['accuracy']):.3f}\")\n",
    "print(f\"\\t- mean f1: {np.mean(metrics['macro_f1']):.3f} +/- {np.std(metrics['macro_f1']):.3f}\")\n",
    "\n",
    "with open(f'{LOG_PATH}multivar.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
